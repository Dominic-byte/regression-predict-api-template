{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    Helper functions for the pretrained model to be used within our API.\n",
    "\n",
    "    Author: Explore Data Science Academy.\n",
    "\n",
    "    Note:\n",
    "    ---------------------------------------------------------------------\n",
    "    Plase follow the instructions provided within the README.md file\n",
    "    located within this directory for guidance on how to use this script\n",
    "    correctly.\n",
    "\n",
    "    Importantly, you will need to modify this file by adding\n",
    "    your own data preprocessing steps within the `_preprocess_data()`\n",
    "    function.\n",
    "    ----------------------------------------------------------------------\n",
    "\n",
    "    Description: This file contains several functions used to abstract aspects\n",
    "    of model interaction within the API. This includes loading a model from\n",
    "    file, data preprocessing, and model prediction.  \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(data):\n",
    "    \"\"\"Private helper function to preprocess data for model prediction.\n",
    "\n",
    "    NB: If you have utilised feature engineering/selection in order to create\n",
    "    your final model you will need to define the code here.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        The data payload received within POST requests sent to our API.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame : <class 'pandas.core.frame.DataFrame'>\n",
    "        The preprocessed data, ready to be used our model for prediction.\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert the json string to a python dictionary object\n",
    "    feature_vector_dict = json.loads(data)\n",
    "    # Load the dictionary as a Pandas DataFrame.\n",
    "    feature_vector_df = pd.DataFrame.from_dict([feature_vector_dict])\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # NOTE: You will need to swap the lines below for your own data\n",
    "    # preprocessing methods.\n",
    "    #\n",
    "    # The code below is for demonstration purposes only. You will not\n",
    "    # receive marks for submitting this code in an unchanged state.\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # ----------- Replace this code with your own preprocessing steps --------\n",
    "    predict_vector = feature_vector_df[['Pickup Lat','Pickup Long',\n",
    "                                        'Destination Lat','Destination Long']]\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    return predict_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path_to_model:str):\n",
    "    \"\"\"Adapter function to load our pretrained model into memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_model : str\n",
    "        The relative path to the model weights/schema to load.\n",
    "        Note that unless another file format is used, this needs to be a\n",
    "        .pkl file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    <class: sklearn.estimator>\n",
    "        The pretrained model loaded into memory.\n",
    "\n",
    "    \"\"\"\n",
    "    return pickle.load(open(path_to_model, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(data, model):\n",
    "    \"\"\"Prepare request data for model prediciton.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        The data payload received within POST requests sent to our API.\n",
    "    model : <class: sklearn.estimator>\n",
    "        An sklearn model object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A 1-D python list containing the model prediction.\n",
    "\n",
    "    \"\"\"\n",
    "    # Data preprocessing.\n",
    "    prep_data = _preprocess_data(data)\n",
    "    # Perform prediction with model and preprocessed data.\n",
    "    prediction = model.predict(prep_data)\n",
    "    # Format as list for output standerdisation.\n",
    "    return prediction[0].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
